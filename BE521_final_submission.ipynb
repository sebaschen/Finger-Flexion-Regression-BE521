{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BUYjhJRzGbVd"
      },
      "source": [
        "# Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iT9KP2PcWhQW"
      },
      "outputs": [],
      "source": [
        "#Set up the notebook environment\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from scipy.stats import pearsonr\n",
        "from scipy import signal as sig\n",
        "from scipy.integrate import simps\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import signal\n",
        "from scipy.signal import butter, filtfilt, welch, stft\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from scipy.io import loadmat, savemat\n",
        "from scipy.integrate import simps\n",
        "from scipy.integrate import simps\n",
        "import warnings\n",
        "import time\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", message=\"arrays to stack must be passed as a \\\"sequence\\\" type such as list or tuple.*\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1kiiM_TmWWKc"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "The traninig data, contains key: \n",
        "  'train_dg': label\n",
        "  'train_ecog': features\n",
        "'''\n",
        "# Training data\n",
        "raw_training_data = loadmat('/Users/lipuchen/penn_homework/BE521/final_project/raw_training_data.mat')\n",
        "\n",
        "# The test data \n",
        "leaderboard_data = loadmat('/Users/lipuchen/penn_homework/BE521/final_project/leaderboard_data.mat')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aglvY895dyd7"
      },
      "source": [
        "# Filter Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nTdX83fdXPt8"
      },
      "outputs": [],
      "source": [
        "def filter_data(raw_eeg, fs=1000):\n",
        "    \"\"\"\n",
        "    Write a filter function to clean underlying data.\n",
        "    Filter type and parameters are up to you. Points will be awarded for reasonable filter type, parameters and application.\n",
        "    Please note there are many acceptable answers, but make sure you aren't throwing out crucial data or adversly\n",
        "    distorting the underlying data!\n",
        "\n",
        "    Input: \n",
        "        raw_eeg (samples x channels): the raw signal\n",
        "        fs: the sampling rate (1000 for this dataset)\n",
        "    Output: \n",
        "        clean_data (samples x channels): the filtered signal\n",
        "    \"\"\"\n",
        "    b = sig.firwin(numtaps=101, cutoff=[0.15, 200], pass_zero='bandpass', fs=fs)\n",
        "    filtered_eeg = filtfilt(b, 1, x = raw_eeg, axis=0)    \n",
        "    return filtered_eeg"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "o6EQ1yIkfUQ6"
      },
      "source": [
        "# Feature extraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uxUTcKgPd-9x"
      },
      "outputs": [],
      "source": [
        "def NumWins(signal, fs, window_len, win_overlap):\n",
        "  length = (signal.shape[0] - window_len * fs)\n",
        "  _olap = win_overlap * fs\n",
        "  return int(1 +  length/ (_olap))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TAvCIeokW70E"
      },
      "outputs": [],
      "source": [
        "def average_time(x):\n",
        "    return np.mean(x, axis=0)\n",
        "def locomotor_potential(x):\n",
        "    \"\"\"\n",
        "        Calculates the locomotor potential feature of the input signal x. \n",
        "        This feature represents the potential for movement-related activity.\n",
        "\n",
        "        Input: \n",
        "        x (window_samples x channels): the window of the filtered ecog signal \n",
        "\n",
        "        Output:\n",
        "        lp (1 x channels): the locomotor potential feature calculated for each channel\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the frequency bands to use for the calculation\n",
        "    freq_bands = [(8, 12), (18, 24), (75, 115), (125, 159), (159, 175)]\n",
        "\n",
        "    # Calculate the power in each frequency band for each channel\n",
        "    freq_power = []\n",
        "    for band in freq_bands:\n",
        "        fmin, fmax = band\n",
        "        power = bandpower(x, fs=1000, fmin=fmin, fmax=fmax)\n",
        "        freq_power.append(power)\n",
        "\n",
        "    # Calculate the locomotor potential feature for each channel\n",
        "    lp = np.mean(freq_power, axis=0)\n",
        "\n",
        "    return lp\n",
        "\n",
        "\n",
        "def bandpower(x, fs, fmin, fmax):\n",
        "    fs = 1000\n",
        "    freqs, psd = sig.welch(x, fs, axis=0, nperseg=x.shape[0])\n",
        "    idx_delta = np.logical_and(freqs >= fmin, freqs <= fmax)\n",
        "    _freq = freqs[1] - freqs[0]\n",
        "    delta_power = simps(psd[idx_delta], dx=_freq, axis=0)    \n",
        "    return delta_power\n",
        "    \n",
        "\n",
        "def spectral_entropy(x, sf, method='fft', nperseg=None, normalize=False, axis=-1):\n",
        "    \"\"\"Calculate the spectral entropy of a signal.\"\"\"\n",
        "    from scipy.signal import welch\n",
        "\n",
        "    x = np.atleast_1d(x)\n",
        "    if len(x) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    # Compute the power spectrum\n",
        "    if method == 'fft':\n",
        "        f, Pxx = welch(x, sf, nperseg=nperseg, axis=axis)\n",
        "    else:\n",
        "        raise ValueError(\"Method must be 'fft'.\")\n",
        "\n",
        "    # Normalize the power spectrum\n",
        "    if normalize:\n",
        "        Pxx /= Pxx.sum()\n",
        "\n",
        "    # Calculate the spectral entropy\n",
        "    spectral_entropy = -np.sum(np.multiply(Pxx, np.log2(Pxx)), axis=axis)\n",
        "\n",
        "    return spectral_entropy\n",
        "\n",
        "\n",
        "def get_features(filtered_window, fs=1000):\n",
        "    \"\"\"\n",
        "        Write a function that calculates features for a given filtered window. \n",
        "        Feel free to use features you have seen before in this class, features that\n",
        "        have been used in the literature, or design your own!\n",
        "\n",
        "        Input: \n",
        "        filtered_window (window_samples x channels): the window of the filtered ecog signal \n",
        "        fs: sampling rate\n",
        "        Output:\n",
        "        features (channels x num_features): the features calculated on each channel for the window\n",
        "    \"\"\"\n",
        "    feat_TimeAvg = average_time(filtered_window)\n",
        "    feat_LMP = locomotor_potential(filtered_window)\n",
        "    return np.hstack([                      \n",
        "                      bandpower(filtered_window, 1000, 5, 15),\n",
        "                      bandpower(filtered_window, 1000, 20, 25),\n",
        "                      bandpower(filtered_window, 1000, 75, 115),\n",
        "                      bandpower(filtered_window, 1000, 125, 160),\n",
        "                      bandpower(filtered_window, 1000, 160, 175),\n",
        "                      feat_TimeAvg])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_An1s9Z_IftZ"
      },
      "outputs": [],
      "source": [
        "def get_windowed_feats(raw_ecog, fs, window_length, window_overlap):\n",
        "    \"\"\"\n",
        "        Write a function which processes data through the steps of filtering and\n",
        "        feature calculation and returns features. Points will be awarded for completing\n",
        "        each step appropriately (note that if one of the functions you call within this script\n",
        "        returns a bad output, you won't be double penalized). Note that you will need\n",
        "        to run the filter_data and get_features functions within this function. \n",
        "\n",
        "        Inputs:\n",
        "        raw_eeg (samples x channels): the raw signal\n",
        "        fs: the sampling rate (1000 for this dataset)\n",
        "        window_length: the window's length\n",
        "        window_overlap: the window's overlap\n",
        "        Output: \n",
        "        all_feats (num_windows x (channels x features)): the features for each channel for each time window\n",
        "            note that this is a 2D array. \n",
        "    \"\"\"\n",
        "    raw_ecog = filter_data(raw_ecog, fs)    \n",
        "    window_disp = window_length - window_overlap\n",
        "    \n",
        "    all_feats = np.vstack([get_features(raw_ecog[int(i * window_disp * fs):int(i * window_disp * fs + window_length * fs), :], fs) for i in range(NumWins(raw_ecog, fs, window_length, window_overlap))])\n",
        "    \n",
        "    return all_feats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "d2bgghxBIm1A"
      },
      "outputs": [],
      "source": [
        "def create_R_matrix(features, N_wind):\n",
        "  \"\"\" \n",
        "  Write a function to calculate the R matrix\n",
        "\n",
        "  Input:\n",
        "    features (samples (number of windows in the signal) x channels x features): \n",
        "      the features you calculated using get_windowed_feats\n",
        "    N_wind: number of windows to use in the R matrix\n",
        "\n",
        "  Output:\n",
        "    R (samples x (N_wind*channels*features))\n",
        "  \"\"\"\n",
        "\n",
        "  features = np.append(features,features[0:N_wind-1, :], axis=0)\n",
        "  n = features.shape[0]\n",
        "  _features = np.append(features[:N_wind-1, :].copy(), features, axis=0)\n",
        "\n",
        "  R = np.stack((_features[i: i+N_wind, :]).reshape(-1) for i in range(n))\n",
        "  _ones = np.ones((n, 1))\n",
        "  R = np.hstack((_ones, R))\n",
        "\n",
        "  return R"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "48KckXBMIaLu"
      },
      "source": [
        "# ML Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QcOAyoP7HDF3"
      },
      "source": [
        "Process the Data and Choose the ratio for the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W-oklNUpaKjN",
        "outputId": "0d896f87-cdf2-4e3a-9f50-a61ddaec47fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_dg\n",
            "train_dg\n",
            "train_dg\n",
            "train_ecog\n",
            "train_ecog\n",
            "train_ecog\n",
            "Number of samples in training set: 300000\n",
            "Number of samples in validate set: 0\n"
          ]
        }
      ],
      "source": [
        "# setup training data and test data\n",
        "# Changed to True if we're doing for validation purpose\n",
        "validate = False\n",
        "if not validate:\n",
        "  training_ratio = 1\n",
        "else:\n",
        "  training_ratio = 0.75\n",
        "\n",
        "\n",
        "train_data = {'train_dg':[], 'train_ecog':[]}\n",
        "validate_data = {'train_dg':[], 'train_ecog':[]}\n",
        "fs = 1000\n",
        "\n",
        "for key in list(raw_training_data)[-2:]:\n",
        "    for i in range(3):\n",
        "        r,c = raw_training_data[key][i][0].shape\n",
        "        train_data[key].append(raw_training_data[key][i][0][:int(r*(training_ratio)), :])\n",
        "        validate_data[key].append(raw_training_data[key][i][0][int(r*(training_ratio)):, :])\n",
        "\n",
        "print(\"Number of samples in training set:\", np.size(train_data['train_ecog'][0][:,0]))\n",
        "print(\"Number of samples in validate set:\", np.size(validate_data['train_ecog'][0][:,0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data['train_dg'][0] = np.delete(train_data['train_dg'][0], 3, 1)\n",
        "train_data['train_dg'][1] = np.delete(train_data['train_dg'][1], 3, 1)\n",
        "train_data['train_dg'][2] = np.delete(train_data['train_dg'][2], 3, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(300000, 4)"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data['train_dg'][2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "e2NT5-yuKIrp"
      },
      "outputs": [],
      "source": [
        "N_wind = 5\n",
        "winLen = 100 / 1e3\n",
        "winOverlap = 50 / 1e3\n",
        "winDisp = winLen - winOverlap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "FV7S0_qyOJJY",
        "outputId": "64d104e1-327a-4f23-c885-615be0700877"
      },
      "outputs": [],
      "source": [
        "\n",
        "predicted_dg = {'predicted_dg': []}\n",
        "\n",
        "if not validate:\n",
        "    for j in range(3):\n",
        "        print('Subject', j)\n",
        "        # create train linear filter\n",
        "        _train_data = train_data['train_ecog'][j]\n",
        "        feature_train = get_windowed_feats(_train_data, 1000, winLen, winOverlap)\n",
        "        R_train = create_R_matrix(feature_train, N_wind)\n",
        "\n",
        "        # the training output label\n",
        "        _Y_train = train_data['train_dg'][j]\n",
        "        _Y_train = sig.resample(_Y_train, R_train.shape[0], axis=0)\n",
        "\n",
        "        # Calculate the linear filter\n",
        "        Y_train = np.vstack([sig.resample(_Y_train[:, i], R_train.shape[0], axis=0) for i in range(5)])\n",
        "        f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train.T)\n",
        "\n",
        "        # Apply regularization\n",
        "        alpha = 5*10**(-4)*0.001\n",
        "        if j == 2:\n",
        "            alpha = 10**(-9)\n",
        "        mean_arr = np.mean(f_train, axis=0)\n",
        "        f_train += alpha * mean_arr\n",
        "\n",
        "        # use linear regression to get initial prediction\n",
        "        test_data = leaderboard_data['leaderboard_ecog'][j][0]\n",
        "        feature_test = get_windowed_feats(test_data, 1000, winLen, winOverlap)\n",
        "        R_test = create_R_matrix(feature_test, N_wind)\n",
        "        prediction_LR_leaderboard = R_test @ f_train\n",
        "\n",
        "        # train XGBoost model\n",
        "        dtrain = xgb.DMatrix(R_train, label=Y_train)\n",
        "\n",
        "        # set up XGBoost hyperparameters\n",
        "        param = {'max_depth': 5, 'eta': 0.3, 'objective': 'reg:squarederror'}\n",
        "        num_round = 20\n",
        "\n",
        "        # train XGBoost model\n",
        "        bst = xgb.train(param, dtrain, num_round)\n",
        "\n",
        "        # use XGBoost model to predict on test data\n",
        "        dtest = xgb.DMatrix(R_test)\n",
        "        prediction_XGB_leaderboard = bst.predict(dtest).reshape((-1, 5))\n",
        "\n",
        "        # combine linear regression and XGBoost predictions\n",
        "        prediction_final_leaderboard = 0.5 * prediction_LR_leaderboard + 0.5 * prediction_XGB_leaderboard\n",
        "        predicted_dg['predicted_dg'].append([prediction_final_leaderboard])\n",
        "\n",
        "    print('Finished model training')\n",
        "\n",
        "else:\n",
        "  performance = []\n",
        "  \n",
        "  for j in range(3):\n",
        "      # print('Subject', j)\n",
        "\n",
        "      # create train linear filter\n",
        "      _train_data = train_data['train_ecog'][j]\n",
        "      feature_train = get_windowed_feats(_train_data, 1000, winLen, winOverlap)\n",
        "      R_train = create_R_matrix(feature_train, N_wind)\n",
        "\n",
        "      # the training output label\n",
        "      _Y_train = train_data['train_dg'][j]\n",
        "      _Y_train = sig.resample(_Y_train, R_train.shape[0], axis=0)\n",
        "\n",
        "      # Calculate the linear filter\n",
        "      Y_train = np.vstack([sig.resample(_Y_train[:, i], R_train.shape[0], axis=0) for i in range(5)])\n",
        "      \n",
        "      f_train = np.linalg.pinv(R_train.T @ R_train) @ (R_train.T @ Y_train.T)\n",
        "      # Apply regularization\n",
        "\n",
        "      alpha = 5*10**(-4)*0.001\n",
        "      if j == 2:\n",
        "          alpha = 10**(-9)\n",
        "      mean_arr = np.mean(f_train, axis=0)\n",
        "      f_train += alpha * mean_arr\n",
        "\n",
        "      # predict on validation data\n",
        "      _validate_data = validate_data['train_ecog'][j]\n",
        "      feature_validate = get_windowed_feats(_validate_data, 1000, winLen, winOverlap)\n",
        "      R_validate = create_R_matrix(feature_validate, N_wind)\n",
        "\n",
        "      # the validation output label\n",
        "      _Y_validate = validate_data['train_dg'][j]\n",
        "      _Y_validate = sig.resample(_Y_validate, R_validate.shape[0], axis=0)\n",
        "\n",
        "      # predict the output\n",
        "      Y_validate = np.vstack([sig.resample(_Y_validate[:, i], R_validate.shape[0], axis=0) for i in range(5)])\n",
        "      prediction_LR_validate = R_validate @ f_train\n",
        "\n",
        "      # calculate performance\n",
        "      perf, _ = pearsonr(prediction_LR_validate.flatten(), Y_validate.T.flatten())\n",
        "      performance.append(perf)\n",
        "\n",
        "      if j != 2:\n",
        "        print('Validation performance for subject', j, ':', perf, tune)\n",
        "  print('Overall validation performance:', np.mean(performance))\n",
        "\n",
        "\n",
        "# Save the predictions\n",
        "savemat('_predicted_dg.mat', predicted_dg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "O9VBLzgEc3kE"
      },
      "outputs": [],
      "source": [
        "savemat('_predicted_dg.mat', predicted_dg)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ronhDWA25Z0o"
      },
      "source": [
        "```\n",
        "alpha = 5*10**(-4)*0.001\n",
        "    if j == 2:\n",
        "      alpha = 10**(-9)\n",
        "```"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0c5dQpQ8mQ2v"
      },
      "source": [
        "0.4260739147939815"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8l_MXBeYAHbA",
        "outputId": "f52bac0e-a0f3-4a2d-c0b2-cb02142aa29d"
      },
      "outputs": [],
      "source": [
        "predicted_dg = {'predicted_dg': []}\n",
        "\n",
        "if not validate:\n",
        "  for j in range(3):\n",
        "\n",
        "    print('Subject', j)\n",
        "    # create train linear filter\n",
        "    _train_data = train_data['train_ecog'][j]\n",
        "    feature_train = get_windowed_feats(_train_data, 1000, winLen, winOverlap)\n",
        "    R_train = create_R_matrix(feature_train, N_wind)\n",
        "    print(R_train.shape)\n",
        "\n",
        "    # the training output label\n",
        "    _Y_train = train_data['train_dg'][j]\n",
        "    _Y_train = sig.resample(_Y_train, R_train.shape[0], axis=0)\n",
        "\n",
        "    # Train XGBoost model on R_train and Y_train\n",
        "    model = xgb.XGBRegressor(n_estimators=100, max_depth=5)\n",
        "    model.fit(R_train, _Y_train)\n",
        "\n",
        "    test_data = leaderboard_data['leaderboard_ecog'][j][0]\n",
        "\n",
        "    # Compute the R matrix for the test data(leaderboard data)  \n",
        "    feature_test = get_windowed_feats(test_data, 1000, winLen, winOverlap)\n",
        "    R_test = create_R_matrix(feature_test, N_wind)\n",
        "    \n",
        "    # Make the predictions using the trained model\n",
        "    prediction_xgb_leaderboard = model.predict(R_test)\n",
        "    \n",
        "    predicted_dg['predicted_dg'].append([prediction_xgb_leaderboard])\n",
        "  \n",
        "  print('Finished Model Training')\n",
        "else:\n",
        "  performance = []\n",
        "  for j in range(3):\n",
        "      print('Subject', j)\n",
        "\n",
        "      # create train linear filter\n",
        "      _train_data = train_data['train_ecog'][j]\n",
        "      feature_train = get_windowed_feats(_train_data, 1000, winLen, winOverlap)\n",
        "      R_train = create_R_matrix(feature_train, N_wind)\n",
        "\n",
        "      # the training output label\n",
        "      _Y_train = train_data['train_dg'][j]\n",
        "      _Y_train = sig.resample(_Y_train, R_train.shape[0], axis=0)\n",
        "\n",
        "      # Train XGBoost model on R_train and Y_train\n",
        "      model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5)\n",
        "      model.fit(R_train, Y_train)\n",
        "\n",
        "      # predict on validation data\n",
        "      _validate_data = validate_data['train_ecog'][j]\n",
        "      feature_validate = get_windowed_feats(_validate_data, 1000, winLen, winOverlap)\n",
        "      R_validate = create_R_matrix(feature_validate, N_wind)\n",
        "\n",
        "      # the validation output label\n",
        "      _Y_validate = validate_data['train_dg'][j]\n",
        "      _Y_validate = sig.resample(_Y_validate, R_validate.shape[0], axis=0)\n",
        "\n",
        "      # predict the output using the trained model\n",
        "      prediction_xgb_validate = model.predict(R_validate)\n",
        "\n",
        "      # calculate performance\n",
        "      perf, _ = pearsonr(prediction_xgb_validate.flatten(), Y_validate.T.flatten())\n",
        "      performance.append(perf)\n",
        "      print('Validation performance for subject', j, ':', perf)\n",
        "\n",
        "  print('Overall validation performance:', performance)\n",
        "\n",
        "# Save the predictions\n",
        "savemat('_predicted_dg.mat', predicted_dg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "y7RZshqPap2T"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "subject 0: shape of dg: (2953, 5)\n",
            "subject 1: shape of dg: (2953, 5)\n",
            "subject 2: shape of dg: (2953, 5)\n"
          ]
        }
      ],
      "source": [
        "if not validate:\n",
        "  # Leveraging this block to upsample to 147000\n",
        "  from scipy.interpolate import interp1d\n",
        "\n",
        "  # load the predicted_dg data\n",
        "\n",
        "  predicted_dg = loadmat('_predicted_dg.mat')['predicted_dg']\n",
        "\n",
        "\n",
        "  upsampled_dg = []\n",
        "  for i in range(3):\n",
        "      subject_dg = predicted_dg[i, 0, :, :]\n",
        "      print(f'subject {i}: shape of dg: {subject_dg.shape}')\n",
        "      upsampled_subject_dg = np.zeros((147500, 5))\n",
        "      for j in range(5):\n",
        "          x = np.arange(subject_dg[:, j].shape[0])\n",
        "          y = subject_dg[:, j]\n",
        "          if i == 2:\n",
        "            f = interp1d(x, y, kind='cubic')  \n",
        "          else:\n",
        "            f = interp1d(x, y, kind='linear')\n",
        "          x_new = np.linspace(0, subject_dg[:, j].shape[0]-1, num=147500)\n",
        "          upsampled_subject_dg[:, j] = f(x_new)\n",
        "      upsampled_dg.append(upsampled_subject_dg)\n",
        "  \n",
        "  upsampled_predicted_dg = {'predicted_dg': np.array(upsampled_dg).reshape((3, 1, 147500, 5))}\n",
        "  savemat('predicted_dg.mat', upsampled_predicted_dg)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OurX3tUn_UbD"
      },
      "outputs": [],
      "source": [
        "# if not validate:\n",
        "\n",
        "#   from scipy.ndimage import gaussian_filter1d\n",
        "#   # Assuming upsampled data is stored in 'upsampled_dg' variable\n",
        "#   smoothed_dg = []\n",
        "#   for i in range(3):\n",
        "#       subject_dg = upsampled_dg[i]\n",
        "#       smoothed_subject_dg = np.zeros((subject_dg.shape[0], 5))\n",
        "#       for j in range(5):\n",
        "#           smoothed_subject_dg[:, j] = gaussian_filter1d(subject_dg[:, j], sigma=7) # present: 7 \n",
        "#       smoothed_dg.append(smoothed_subject_dg)\n",
        "\n",
        "#   # Replace upsampled data with smoothed data\n",
        "#   upsampled_dg = smoothed_dg\n",
        "#   # save the upsampled predicted_dg data\n",
        "#   upsampled_predicted_dg = {'predicted_dg': np.array(upsampled_dg).reshape((3, 1, 147500, 5))}\n",
        "#   savemat('predicted_dg.mat', upsampled_predicted_dg)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51wjlxuv9SoU",
        "outputId": "eb217185-5e79-4876-8a9a-c6180459cc71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3, 1, 147500, 5)\n"
          ]
        }
      ],
      "source": [
        "# Print to check if this upsaple is good for shape: (3, 1, 147500, 5)\n",
        "if not validate:\n",
        "  up_x = loadmat('predicted_dg.mat')\n",
        "  print(up_x['predicted_dg'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwAFv1vmSrBf"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Assuming upsampled data is stored in 'upsampled_dg' variable\n",
        "# fig, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
        "# sigmas = [1, 32]\n",
        "\n",
        "# for i in range(3):\n",
        "#     subject_dg = upsampled_dg[i]\n",
        "#     axs[i//2, i%2].plot(subject_dg[:, 0], label='Original')\n",
        "#     for sigma in sigmas:\n",
        "#         smoothed_subject_dg = gaussian_filter1d(subject_dg[:, 0], sigma=sigma)\n",
        "#         axs[i//2, i%2].plot(smoothed_subject_dg, label=f'Sigma = {sigma}')\n",
        "#     axs[i//2, i%2].set_title(f'Subject {i}')\n",
        "#     axs[i//2, i%2].legend()\n",
        "\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCeSIqfECFCA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
